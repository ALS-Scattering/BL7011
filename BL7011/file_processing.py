"""
    This file contains functions to load and extract Nexus data written in the
    HDF5 (.h5) format. These functions are specifically written to handle
    the data generated by the COSMIC Scattering endstation at ALS BL 7.0.1.1.

    Authors: Dayne Sasaki, Damian GÃ¼nzing
"""

import numpy as np
from glob import glob
from os.path import basename
import nexusformat.nexus
import pandas as pd
import h5py


def get_all_file_names(
        path_dir: str,
        *,
        search: str = '',
        verbose: bool = True,
):
    """
    Gets all the names of files with an ".h5" extension in the directory
    "path_dir" and stores the associated paths in a dictionary.

    PARAMETERS
    -----
    path_dir: str
        The pathname of the directory (i.e., folder) which contains the h5 data
    search: str
        "search" is a string that the function will look for in the different
        file names. Specifying "search" will cause the function to only return
        those file names which contain the specified string.
    verbose: bool
        If set to True, the function will print out the names of each file
        along  with its associated index in the dictionary. By default this is
        set to True.

    RETURNS
    -----
    path_file: dict[int, str]
        A dictionary containing path names of h5 files, sorted in descending
        file name
    """

    # Get a dictionary of ".h5" file path names
    path_file: dict[int, str] = dict(
        (index, path)  # Get both the h5 file path and index...
        for index, path  # ... for all h5 file paths and indices...
        in enumerate(sorted(glob(path_dir + '*.h5')))  # ... in the directory..
        if search in path)  # ... if the h5 file has the phrase in "search"

    # Line-by-line, print out the collected base names (i.e., file name)
    # and associated indices if verbose is set to True
    if verbose:
        print('Index \t File name')
        for key in path_file.keys():
            print(key, '\t', basename(path_file[key]))

    return path_file


def get_labview_ccd_groups(
        hdf5_group_instrument: h5py._hl.dataset.Dataset,
) -> h5py._hl.dataset.Dataset:
    """
        Access and store HDF5 Group 'labview_data' and 'detector_1' under the
        path /entry1/instrument_1/

        i.e., hdf5_group_instrument from the statement below:
            with h5py.file(<file name>, 'r') as h5_file:
                hdf5_group_statement = h5_file

        PARAMETERS
        -----
        hdf5_group: h5py._hl.dataset.Dataset
            A HDF5 file object

        index: int
            Index of the image within an image stack in the HDF5 file

        correction: str
            Type of intensity correction to perform on the CCD image 'ccd_image'
                - Nothing : Return the raw ccd image
                - 'i0 norm' : Normalize ccd image by the right blade current
                - 'cps' : Normalize ccd image by acquisition time (counts per sec)

        RETURNS
        -----
        ccd_image: np.ndarray
            A M x N image

        TODO: Finish writing this up you dingus!
        """
    return None


def get_single_ccd_image(
        dataset: h5py._hl.dataset.Dataset,
        index: int,
        correction: str = ''
) -> np.ndarray:
    """
    Get a CCD image contained in a HDF5 dataset of interest with optional
    normalization of the image
    
    PARAMETERS
    -----
    dataset: h5py._hl.dataset.Dataset
        An HDF5 dataset accessed down to the ['instrument_1'] key
        i.e., h5_file['entry1']['instrument_1']

    index: int
        Index of the image within an image stack in the HDF5 file

    correction: str
        Type of intensity correction to perform on the CCD image 'ccd_image'
            - Nothing : Return the raw ccd image
            - 'i0 blade' : Normalize ccd image by the right blade current
            - 'i0 rlrl' : Normalized by the XS111 RLRL diode (what is this?)
            - 'cps' : Normalize ccd image by acquisition time (counts per sec)

    RETURNS
    -----
    ccd_image: np.ndarray
        A M x N image

    TODO: Change the normalization factor for the diode, they're negative!
          Plus, the number of labview datapoints is not the same as the ccd
          data points.
    """
    # Define the h5 database with the ccd image stack and the labview data
    h5_ccd_db = dataset['detector_1']['data']
    h5_labview_db = dataset['labview_data']

    # Get the image
    ccd_image = (h5_ccd_db[index]).astype(float)

    # Select what kind of normalization to perform on the image
    if 'i0 blade' in correction:  # Blade current i0 normalization
        norm_factor = h5_labview_db['XS111LeftBladecurrent_diode'][index]
    elif 'i0 rlrl' in correction:  # XS111 RLRL diode normalization
        print(h5_labview_db['XS111RLRL_diode'].shape)
        norm_factor = -h5_labview_db['XS111RLRL_diode'][index]
        print(norm_factor)
    elif 'cps' in correction:  # Convert intensity to counts-per-second
        norm_factor = h5_labview_db['count_time'][index] / 1000
    elif '' in correction:
        norm_factor = 1
    else:
        raise ValueError('An invalid correction method has been specified.')

    # Normalize the image by either i0 or acquisition time
    return ccd_image / norm_factor


def store_h5_ccd_image(
        path_file: str,
        correction: str = ''
) -> np.ndarray:
    """
    Reads the CCD image contained in a h5 file of interest

    If an image stack with "v" images is fed into this function, the function
    will perform calculations on the individual images

    PARAMETERS
    -----
    path_file: str
        The pathname of the h5 file

    correction: str
        Type of intensity correction to perform on the CCD image 'ccd_image'
            - Nothing : Return the raw ccd image
            - 'i0 blade' : Normalize ccd image by the right blade current
            - 'i0 RLRL' : Normalized by the XS111 RLRL diode (what is this?)
            - 'cps' : Normalize ccd image by acquisition time (counts per sec)

    RETURNS
    -----
    ccd_image: np.ndarray
        The CCD image, contained within an v x M x N array
    """
    # Open the h5 file of interest
    with h5py.File(path_file, 'r') as h5_file:
        # Define the h5 database with the ccd image stack and the labview data
        h5_inst_db = h5_file['entry1']['instrument_1']
        h5_ccd_db = h5_inst_db['detector_1']['data']
        h5_labview_db = h5_inst_db['labview_data']

        # Generate numpy array to store the CCD images
        number_images = h5_ccd_db.shape[0]  # Number of images in the stack
        number_pixels = h5_ccd_db.shape[2]  # Number of pixels in row/col
        ccd_image = np.empty([number_images, number_pixels, number_pixels])

        # Iterate through all the individual images in the stack
        for index in range(number_images):
            # Get the image
            ccd_image[index] = get_single_ccd_image(h5_inst_db, index, correction)

    return ccd_image

def batch_file_processing(
        path_dir: str,
        *,
        labview_simiar: tuple[str],
        labview_dissimilar: tuple[str],
        search: str = '',
        correction: str = '',
        verbose: bool = True,
        diagnostic: bool = False,
) -> None:
    """
    TODO:
    - Make sure that the different indices associated with the file grabbing
    doesn't screw up the operation of the code
    - Make certain parts (i.e., pair processing) their own dedicated functions
    - Ability to save result data

    Performs batch processing of all COSMIC Scattering data files within a
    specified directory.

    This function specifically looks at all the h5 files within a directory
    and groups them based on similar/dissimilar metadata they share (e.g.,
    polarization, energy, angle) which must be specified by the user. Several
    operations (specified by the user) will be evaluated using all the data
    files within a group

    Examples
        - Dichroism calculated between pairs of different polarizations

    ASSUMPTIONS
    -----
    1) Within each pair of polarization images, the images...
        a) were captured at identical 2theta and detector_translate positions,
            where both values are rounded to the second decimal place
        b) share a similar name
    2) Between pairs of polarizations, the image sets...
        a) don't share common terms specified in 'search'
    3) If each file contains more than one image, it is assumed that those
       those images were taken for averaging (statistics) purposes

    PARAMETERS
    -----
    path_dir: str
        The pathname of the directory (i.e., folder) which contains the h5 data

    labview_similar: tuple[str]
        Labview keys which will be similar for the operations

    labview_dissimilar: tuple[str]
        Labview keys which will be dissimilar for the operations
        These keys will define the individual file groups


    search: str
        "search" is a string that the function will look for in the different file names.
        Specifying "search" will cause the function to only return those file names which
        contain the specified string.

    save_file: bool
        If enabled, will

    verbose: bool
        If set to True, the function will print out a list of the acquired file paths along with
        the associated polarization, 2theta, and detector position values. By default this is
        set to True.

    diagnostic: bool
        Similar to verbose, but displays some additional pandas dataframes. Namely,
        file_properties and unique_det_positions

    RETURNS
    -----
    Nothing yet

    """
    # This is used to visualize all the entries within a pandas dataframe
    pd.set_option('display.max_colwidth', 0)

    # Grab all the file names in the directory and put them in a dict
    file_paths = get_all_file_names(path_dir,
                                    search=search,
                                    verbose=True)

    # Convert file_paths into a Pandas DataFrame
    file_properties = pd.DataFrame(file_paths).T

    # Create empty columns in file_properties to later fill with labview
    # data associated with each file path
    for entry in labview_simiar + labview_dissimilar:
        file_properties[entry] = pd.Series(dtype='float')

    # Populate file_properties with the desired labview data (labview_similar
    # and labview_dissimilar)
    for idx in file_properties.index:
        # Open one h5 file at a time
        with h5py.File(file_paths[key], 'r') as h5_file:
            # Iterate over all the labview_similar and labview_dissimilar
            # entries
            for entry in labview_similar + labview_dissimilar:
                file_properties[entry] = round(h5_file['entry1']
                                               ['instrument_1']
                                               ['labview_data']
                                               [entry]
                                               [0], 2)

    # Update the column names
    tup_keys = tuple(1 + range(len(labview_simiar + labview_dissimilar)))
    tup_val = tuple(('path') + labview_simiar + labview_dissimilar)
    file_properties = file_properties.rename(
        columns=dict(zip(tup_keys, tup_val)))

    # Displays file_properties if diagnostic is enabled
    if diagnostic:
        print('-------------------------------------\nfile_properties')
        display(file_properties.sort_values(
            by=['tth', 'det translate', 'polarization']))

    # Get a smaller dataframe which lists the unique combinations of 2Theta
    # and Det translate in the file_properties.
    unique_det_positions = file_properties.groupby(
        ['tth', 'det translate']).size().reset_index().rename(
        columns={0: 'counts'})

    # Get rid of any entries in unique_2Theta_Det_translate which have counts less than or equal to 1
    # since we need 2 images with different polarizations to do dichroism calculations
    unique_det_positions = unique_det_positions.drop(
        unique_det_positions.loc[unique_det_positions['counts'] <= 1].index)

    # Displays unique_det_positions if diagnostic is enabled
    if diagnostic:
        print('-------------------------------------\nunique_det_positions')
        display(unique_det_positions)
        print('\n-------------------------------------\n')

    ### At this point, unique_det_positions contains all the unique tth and det_translate positions
    ### which we can use to pull up the two CCD files we need for dichroism calculation

    # Iterate through all the entries in unique_det_positions.
    for idx in unique_det_positions.index.values:
        # Store the current tth and det_translate values we're looking at in variables
        current_tth = unique_det_positions.loc[idx]['tth']
        current_det_translate = unique_det_positions.loc[idx]['det translate']

        # Pull out the files which have the correct tth and det translate values
        file_set = file_properties.loc[
            (file_properties['tth'] == current_tth) &
            (file_properties['det translate'] == current_det_translate)]

        # Pull out the files which have the 2 desired polarization states
        idx_state_1 = file_set.loc[
            file_properties['polarization'] == POLARIZATION_STATE[
                0]].index.values
        idx_state_2 = file_set.loc[
            file_properties['polarization'] == POLARIZATION_STATE[
                1]].index.values

        # Only perform subsequent calculations if both file_state_* have exactly one entry
        if idx_state_1.shape[0] == 1 and idx_state_2.shape[0] == 1:

            # If verbose is enabled, print out the dataframe
            if verbose:
                print('\n')
                display(
                    file_set.loc[np.concatenate((idx_state_1, idx_state_2))])

            # Pull out the image file paths from the dataframe
            file_path_1 = file_set.loc[idx_state_1]['file path'].values[0]
            file_path_2 = file_set.loc[idx_state_2]['file path'].values[0]
            ccd_state_1 = get_h5_ccd_image(file_path_1, correction)
            ccd_state_2 = get_h5_ccd_image(file_path_2, correction)

    # Let user know the function is done
    print('Function is done. D-U-N')
    return file_properties
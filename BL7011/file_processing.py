"""
    This file contains functions to load and extract Nexus data written in the
    HDF5 (.h5) format. These functions are specifically written to handle
    the data generated by the COSMIC Scattering endstation at ALS BL 7.0.1.1.

    Authors: Dayne Sasaki, Damian GÃ¼nzing
"""
import os.path

import numpy as np
from glob import glob
from os.path import basename
import pandas as pd
import h5py
from IPython.display import display
from BL7011 import data_processing as dp
from BL7011 import plotting as plt


def get_all_file_names(
        path_dir: str,
        *,
        search: str = '',
        verbose: bool = True,
) -> dict[int, str]:
    """
    Gets all the names of files with an ".h5" extension in the directory
    "path_dir" and stores the associated paths in a dictionary.

    PARAMETERS
    -----
    path_dir: str
        The pathname of the directory (i.e., folder) which contains the h5 data
    search: str
        "search" is a string that the function will look for in the different
        file names. Specifying "search" will cause the function to only return
        those file names which contain the specified string.
    verbose: bool
        If set to True, the function will print out the names of each file
        along  with its associated index in the dictionary. By default, this is
        set to True.

    RETURNS
    -----
    path_file: dict[int, str]
        A dictionary containing path names of h5 files, sorted in descending
        file name
    """
    # Get a dictionary of ".h5" file path names
    path_file = dict(
        (index, path)  # Get both the h5 file path and index...
        for index, path  # ... for all h5 file paths and indices...
        in enumerate(sorted(glob(path_dir + '*.h5')))  # ... in the directory..
        if search in path)  # ... if the h5 file has the phrase in "search"

    # Line-by-line, print out the collected base names (i.e., file name)
    # and associated indices if verbose is set to True
    if verbose:
        print('Index \t File name')
        for key in path_file.keys():
            print(key, '\t', basename(path_file[key]))

    return path_file


def dict_to_df(
        path_dict: dict[int, str],
        *,
        value_title: str = '',
        verbose: bool = False
) -> pd.DataFrame:
    """
    Takes a dictionary of and saves it as a Pandas data frame. This function
    is largely intended to use with get_all_file_names to convert dictionaries
    with path names into a Pandas data frame.

    Parameters
    ----------
    path_dict: dict[int,str]
        Dictionary of integer (keys) and file path names (values) (e.g., the
        output from get_all_file_names)
    value_title: str
        Sets the name of the column containing the values
    verbose: boolean
        Shows the pandas data frame

    Returns
    -------
    path_df: pd.DataFrame
        A Pandas data frame
    """
    # Convert file_dict into a Pandas DataFrame
    path_df = pd.DataFrame(path_dict, index=[0]).T

    # Change the '0' column name to value_title
    path_df.rename(columns={0: value_title}, inplace=True)

    if verbose:
        # This is used to visualize all the entries within a pandas dataframe
        pd.set_option('display.max_colwidth', 0)

        # Show the pandas df
        display(path_df)

    return path_df


def read_image_from_h5(
        dataset: h5py._hl.dataset.Dataset,
        index: int,
        correction: str = ''
) -> np.ndarray:
    """
    Reads CCD image(s) contained in a HDF5 dataset of interest with optional
    normalization of the image
    
    PARAMETERS
    -----
    dataset: h5py._hl.dataset.Dataset
        An HDF5 dataset accessed down to the ['instrument_1'] key
        i.e., h5_file['entry1']['instrument_1']

    index: int
        Index of the image within an image stack in the HDF5 file

    correction: str
        Type of intensity correction to perform on the CCD image 'ccd_image'
            - Nothing : Return the raw ccd image
            - 'i0 blade' : Normalize ccd image by the right blade current
            - 'i0 rlrl' : Normalized by the XS111 RLRL diode (what is this?)
            - 'cps' : Normalize ccd image by acquisition time (counts per sec)

    RETURNS
    -----
    ccd_image: np.ndarray
        A v x M x N image

    TODO: Change the normalization factor for the diode, they're negative!
          Plus, the number of labview datapoints is not the same as the ccd
          data points.
    """
    # Define the h5 database with the ccd image stack and the labview data
    h5_ccd_db = dataset['detector_1']['data']
    h5_labview_db = dataset['labview_data']

    # Get the image
    ccd_image = (h5_ccd_db[index]).astype(float)

    # Select what kind of normalization to perform on the image
    if 'i0 blade' in correction:  # Blade current i0 normalization
        norm_factor = h5_labview_db['XS111LeftBladecurrent_diode'][index]
    elif 'i0 rlrl' in correction:  # XS111 RLRL diode normalization
        print(h5_labview_db['XS111RLRL_diode'].shape)
        norm_factor = np.abs(h5_labview_db['XS111RLRL_diode'][index])
        print(norm_factor)
    elif 'cps' in correction:  # Convert intensity to counts-per-second
        norm_factor = h5_labview_db['count_time'][index] / 1000
    elif '' in correction:
        norm_factor = 1
    else:
        raise ValueError('An invalid correction method has been specified.')

    # Normalize the image by either i0 or acquisition time
    return ccd_image / norm_factor


def load_h5_image(
        path_file: str,
        correction: str = ''
) -> np.ndarray:
    """
    Reads the CCD image contained in a h5 file of interest

    If an image stack with "v" images is fed into this function, the function
    will perform calculations on the individual images

    PARAMETERS
    -----
    path_file: str
        The pathname of the h5 file

    correction: str
        Type of intensity correction to perform on the CCD image 'ccd_image'
            - Nothing : Return the raw ccd image
            - 'i0 blade' : Normalize ccd image by the right blade current
            - 'i0 RLRL' : Normalized by the XS111 RLRL diode (what is this?)
            - 'cps' : Normalize ccd image by acquisition time (counts per sec)

    RETURNS
    -----
    ccd_image: np.ndarray
        The CCD image, contained within an v x M x N array
    """
    # Open the h5 file of interest
    with h5py.File(path_file, 'r') as h5_file:
        # Define the h5 database with the ccd image stack and the labview data
        h5_inst_db = h5_file['entry1']['instrument_1']

        # Get the ccd_image stack
        ccd_image = read_image_from_h5(h5_inst_db, 0, correction)
    return ccd_image


def get_file_groups(
        path_dir: str,
        *,
        key_common: str | tuple[str],
        key_variable: str,
        search: str = '',
        verbose: bool = False
) -> tuple[pd.DataFrame, pd.DataFrame, list[bool]]:
    """
        Looks at all HDF5 CCD files within a directory and identifies
        determines groups of files ("file groups") which share desired 
        combinations of similar and dissimilar HDF5 keys ("metadata").

        The function outputs a dictionary, where each key:value pair
        corresponds with a single file group. The dictionary values contain
        Pandas Dataframe containing the file paths and relevant metadata for
        each individual file within the file group.

        Given a list of HDF5 keys, this function will determine all unique
        combinations of HDF5 key values and search for files which share
        these common characteristics; this defines a file group.

        ASSUMPTIONS
        -----
        1) The individual files within a file group share similar names (i.e.,
            the names are not 100% different)

        PARAMETERS
        -----
        path_dir: str
            The pathname of the directory (i.e., folder) which contains the h5

        key_common: str or tuple[str]
            HDF5 keys/Labview entries which are common to a group of data files

        key_variable: str
            HDF5 keys/Labview entry which is differ between the individual
            files within a file group

        search: str
            "search" is a string that the function will look for in the
            different file names. Specifying "search" will cause the function
            to only return those file names which contain the specified string.

        verbose: bool
            Will enable/disable the outputs of get_all_file_names and
            dict_to_df in the function

        RETURNS
        -----
        (file_list, unique_positions, file_group): tuple
            file_df: pd.DataFrame
                Data frame with list of path names along with their associated
                key_common and key_variable position values
            unique_positions: pd.DataFrame
                Data frame containing the unique key_common and key_variable
                position value combinations observed across all the files.
                EACH ROW IN UNIQUE_POSITION REPRESENTS PARAMETERS SHARED
                BY A FILE GROUP
            file_group: list[pd.Series] (dtype boolean)
                Indicates which rows in file_df belong to a file_group
                (i.e., a row in unique_positions)
                For instance, file_df[file_group[0]] will pull all
                the files which possesses position value combinations in
                unique_positions.loc[[0]]
    """
    # This is used to visualize all the entries within a pandas dataframe
    pd.set_option('display.max_colwidth', 0)

    # Grab all the file names in the directory and put them in a dict
    file_paths = get_all_file_names(path_dir, search=search, verbose=verbose)

    # Convert file_paths into a Pandas DataFrame
    file_df = dict_to_df(file_paths, value_title='path', verbose=verbose)

    # Check if keys_common and/or key_variable are tuples or str.
    # If they are strings, then convert them to tuples.
    if isinstance(key_common, str):
        key_common = (key_common,)

    if isinstance(key_variable, str):
        key_variable = (key_variable,)

    # Create empty columns in file_df to later fill with labview
    # data associated with each file path
    for entry in key_common + key_variable:
        file_df[entry] = pd.Series(dtype='float')

    # Populate file_df with the desired labview data (keys_common
    # and keys_different)
    for idx in file_df.index:
        # Open one h5 file at a time
        with h5py.File(file_paths[idx], 'r') as h5_file:
            # Iterate over all the keys_common and keys_different entries
            for entry in key_common + key_variable:
                file_df.at[idx, entry] = round(h5_file['entry1']
                                               ['instrument_1']
                                               ['labview_data']
                                               [entry]
                                               [0], 2)

    # Get a smaller dataframe with lists the unique combination of key_common
    # position values (not the name of the key, but the value associated with
    # it)  along with number of files which possess those values (i.e., the
    # number of file group members, which is also the number of key_variable
    # files within the file group)
    unique_positions = \
        file_df.groupby(
            list(key_common)).size().reset_index().rename(
            columns={0: 'counts'})

    # Generate a 1 x N list of Pandas series (dtype boolean, 1 x M) which can
    # be used to pull select parts of file_df (M) based on a desired
    # set of unique_position values (N)

    # First, generate a L x N list of series booleans which come from logical
    # statements (such as "detector_rotate == 6.0") for key_common values (L)
    # and their associated position values (N)
    # len(equal_table) = # of key_common values (L)
    # len(equal_table[0]) = # of unique_positions (N)
    # len(equal_table[0][0]) = # of individual files in file_df
    equal_table = [[file_df[col_name] == value for value in
                    unique_positions[col_name]] for col_name in key_common]

    # Reduce the table into a 1 X N list
    # Start off by pulling the first column of equivalency_table
    file_group = equal_table[0]
    # Perform logical operation across the key_common values (N) for each
    # unique_position (M)
    for compare_list in equal_table:
        file_group = [file_group[count] & compare_value
                      for count, compare_value in enumerate(compare_list)]

    # K, we're dun
    return file_df, unique_positions, file_group


def batch_processing_dichroism(
        path_dir: str,
        *,
        key_common: str | tuple[str],
        key_variable: str,
        search: str = '',
        mode: str = 'difference',
        correction: str = '',
        variable_stack: bool = False,
        verbose: bool = False,
        diagnostic: bool = False,
        save_data: bool = True,
        save_figure: bool = False
) -> None:
    """
    Performs batch processing of all COSMIC Scattering data files within a
    specified directory.

    This function specifically looks at all the h5 files within a directory
    and groups them based on similar/dissimilar metadata they share (e.g.,
    polarization, energy, angle) which must be specified by the user. The files
    within a group will be processed using user-defined functions in the
    files within a group

    Possible thing to include:
    Try/catch statement for handling data files with where_is_my_frame_missing
    Include a repair function to handle broken h5 files

    Examples
        - Dichroism calculated between pairs of different polarizations

    ASSUMPTIONS
    -----
    1) Within each pair of polarization images, the images...
        a) were captured at identical 2theta and detector_translate positions,
            where both values are rounded to the second decimal place
        b) share a similar name
    2) Between pairs of polarizations, the image sets...
        a) don't share common terms specified in 'search'
    3) If each file contains more than one image, it is assumed that those
       those images were taken for averaging (statistics) purposes

    PARAMETERS
    -----
    path_dir: str
        Pathname of the directory (i.e., folder) which contains the h5 files

    key_common: str or tuple[str]
        HDF5 keys/Labview entries which are common to a group of data files.

    key_variable: str or tuple[str]
        HDF5 keys/Labview entry which is different across the entire
        collection of data files to be examined.

    search: str
        "search" is a string that the function will look for in the different
        file names. Specifying "search" will cause the function to only return
        those file names which contain the specified string.

    mode: str
        The type of dichroism calculation to perform
        - 'difference': Calculates image as (image_pol_A - image_pol_B)
        - 'asymmetry': Calculates image as
                      (image_pol_A - image_pol_B) / (image_pol_A + image_pol_B)

    correction: str
        Type of intensity correction to perform on the CCD image 'ccd_image'
            - Nothing : Return the raw ccd image
            - 'i0 blade' : Normalize ccd image by the right blade current
            - 'i0 RLRL' : Normalized by the XS111 RLRL diode (what is this?)
            - 'cps' : Normalize ccd image by acquisition time (counts per sec)

    variable_stack: bool
        Setting this to False will make the function calculate an average
        of an image stack (i.e., each frame in the stack represents multiple
        "redundant" camera exposure and do not have any parameters varying)

    verbose: bool
        If set to True, the function will print out a list of the acquired file
        paths along with the associated polarization, 2theta, and detector
        position values. By default this is set to True

    diagnostic: bool
        Similar to verbose, but displays some additional pandas dataframes.
        Namely, file_df and unique_det_positions

    save_data: bool
        Saves the processed data. Data files will automatically have a name
        generated based on the "key_common" and "key_variable" names and values
        they possess

    save_figure: bool
        Saves the matplotlib figures generated during batch processing. Files
        will automatically have a name generated based on the "keys_common" and
        "key_variable" name and values they possess

    RETURNS
    -----
    Nothing

    """

    # Define static variables to identify polarization states
    POL_CIR = (-1, 1)
    POL_LIN = (0, 2)

    # Define a private function to handle saving data
    def data_saver(path_name,
                   im_dichro,
                   im_pol_a,
                   im_pol_b,
                   metadata_pol_a,
                   metadata_pol_b
                   ) -> None:
        # Writes the processed data to an HDF5 file
        with h5py.File(path_name, 'w') as hf:
            # Create different groups for the dichroism image and the
            # corresponding polarization images
            g_process = hf.create_group('process')
            g_pol_a = hf.create_group('pol_a')
            g_pol_b = hf.create_group('pol_b')

            # Save the images
            g_process.create_dataset('image_dichro', data=im_dichro)
            g_pol_a.create_dataset('image', data=im_pol_a)
            g_pol_b.create_dataset('image', data=im_pol_b)

            # Save the metadata.
            for entry_name in metadata_pol_a.columns[:]:
                g_pol_a.create_dataset(entry_name,
                                       data=metadata_pol_a[entry_name].iloc[0])

            for entry_name in metadata_pol_b.columns[:]:
                g_pol_b.create_dataset(entry_name,
                                       data=metadata_pol_b[entry_name].iloc[0])

            # Save image processing parameters
            g_process.create_dataset('correction', data=correction)
            g_process.create_dataset('dichroism_calculation', data=mode)

    # Define a private function to handle file name generation from metadata.
    # The file name will exclude the key_variable from the name
    def file_name_generator(prefix, f_df) -> str:
        # Generate name for dichroism data file
        col_names = f_df.columns[1:-1]
        temp_file_name = prefix + ''.join(
            f'_{idx_name}_{f_df[idx_name].iloc[0]}' for
            idx_name in col_names).replace('.', 'p') + '.h5'
        return os.path.join(path_dir, temp_file_name)

    # Use group_files_in_dir to determine what groups of files to perform
    # batch processing on
    file_df, unique_positions, file_group = \
        get_file_groups(path_dir,
                        key_common=key_common,
                        key_variable=key_variable,
                        search=search,
                        verbose=diagnostic)

    # Display files_df and unique_positions if diagnostic is True
    if diagnostic:
        print('------------------file_df------------------\n')
        display(file_df)
        print('\n------------------unique_positions------------------\n')
        display(unique_positions)
        print('\n-------------------------------------\n')

    # Look at each file group one at a time and perform dichroism calculations
    for idx, position_values in enumerate(unique_positions):
        # Pull out the dataframe containing all members of the file group
        file_group_df = file_df[file_group[idx]]

        # Determine if this file group is suitable to calculate dichroism
        file_LCP = file_group_df[file_group_df[key_variable] == POL_CIR[0]]
        file_RCP = file_group_df[file_group_df[key_variable] == POL_CIR[1]]
        file_HLP = file_group_df[file_group_df[key_variable] == POL_LIN[0]]
        file_VLP = file_group_df[file_group_df[key_variable] == POL_LIN[1]]

        # Dichroism calculation can only be performed if each opposite
        # polarization has only 1 image
        if len(file_LCP) * len(file_RCP) == 1:
            # Calculate dichroism image
            im_XCD, im_RCP, im_LCP = \
                dp.calculate_dichroism_from_file(file_RCP['path'].values[0],
                                                 file_LCP['path'].values[0],
                                                 mode=mode,
                                                 correction=correction,
                                                 variable_stack=variable_stack)

            # Generate name for dichroism data file
            save_path = file_name_generator('processed_XCD', file_RCP)

            # If verbose, display file_LCP and file_RCP
            if verbose:
                display(file_group_df[np.abs(
                    file_group_df[key_variable]) == 1])

            # Plot the dichroism data
            plt.plot_three_images_dichroism(im_RCP, im_LCP, im_XCD,
                                            title_main=save_path,
                                            title_1='RCP',
                                            title_2='LCP',
                                            title_3='XCD')

            if save_data:
                print('Saving data to: ' + save_path)
                # Save the dichroism data
                data_saver(save_path, im_XCD, im_RCP, im_LCP, file_RCP,
                           file_LCP)
                print('\nData saved')
                print('\n-------------------------------------\n')

        if len(file_HLP) * len(file_VLP) == 1:
            # Calculate dichroism image
            im_XLD, im_HLP, im_VLP = \
                dp.calculate_dichroism_from_file(file_HLP['path'].values[0],
                                                 file_VLP['path'].values[0],
                                                 mode=mode,
                                                 correction=correction,
                                                 variable_stack=variable_stack)

            # Generate name for dichroism data file
            save_path = file_name_generator('processed_XLD', file_HLP)

            # If verbose, display file_HLP and file_VLP
            if verbose:
                display(file_group_df[
                            (file_group_df[key_variable] == POL_LIN[0]) |
                            (file_group_df[key_variable] == POL_LIN[1])])

            # Plot the dichroism data
            plt.plot_three_images_dichroism(im_HLP, im_VLP, im_XLD,
                                            title_main=save_path,
                                            title_1='HLP',
                                            title_2='VLP',
                                            title_3='XLD')

            if save_data:
                print('Saving data to: ' + save_path)
                # Save the dichroism data
                data_saver(save_path, im_XLD, im_HLP, im_VLP, file_HLP,
                           file_VLP)
                print('\nData saved')
                print('\n-------------------------------------\n')

    # Let user know the function is done
    print('Function is done. D-U-N')
